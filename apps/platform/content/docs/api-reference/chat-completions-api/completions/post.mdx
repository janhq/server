---
title: Create a chat completion
description: >-
  Generates a model response for the given chat conversation. This is a standard
  chat completion API that supports both streaming and non-streaming modes
  without conversation persistence.


  **Streaming Mode (stream=true):**

  - Returns Server-Sent Events (SSE) with real-time streaming

  - Streams completion chunks directly from the inference model

  - Final event contains "[DONE]" marker


  **Non-Streaming Mode (stream=false or omitted):**

  - Returns single JSON response with complete completion

  - Standard OpenAI ChatCompletionResponse format


  **Storage Options:**

  - `store=true`: Persist the latest input message and assistant response to the
  active conversation

  - `store_reasoning=true`: Additionally persist reasoning content provided by
  the model

  - When `store` is omitted or false, the conversation remains read-only


  **Features:**

  - Supports all OpenAI ChatCompletionRequest parameters

  - Optional conversation context for conversation persistence

  - User authentication required

  - Direct inference model integration
full: true
_openapi:
  method: POST
  route: /v1/chat/completions
  toc: []
  structuredData:
    headings: []
    contents:
      - content: >-
          Generates a model response for the given chat conversation. This is a
          standard chat completion API that supports both streaming and
          non-streaming modes without conversation persistence.


          **Streaming Mode (stream=true):**

          - Returns Server-Sent Events (SSE) with real-time streaming

          - Streams completion chunks directly from the inference model

          - Final event contains "[DONE]" marker


          **Non-Streaming Mode (stream=false or omitted):**

          - Returns single JSON response with complete completion

          - Standard OpenAI ChatCompletionResponse format


          **Storage Options:**

          - `store=true`: Persist the latest input message and assistant
          response to the active conversation

          - `store_reasoning=true`: Additionally persist reasoning content
          provided by the model

          - When `store` is omitted or false, the conversation remains read-only


          **Features:**

          - Supports all OpenAI ChatCompletionRequest parameters

          - Optional conversation context for conversation persistence

          - User authentication required

          - Direct inference model integration
---

{/* This file was generated by Fumadocs. Do not edit this file directly. Any changes should be made by running the generation command again. */}

<APIPage document={"./api/server.yaml"} operations={[{"path":"/v1/chat/completions","method":"post"}]} webhooks={[]} hasHead={false} />